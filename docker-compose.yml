version: '3.9'

services:
  api:
    build: .
    container_name: predictive_api
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    depends_on:
      - mlflow

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlflow_tracking
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=./mlruns
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=./mlruns
    volumes:
      - ./mlruns:/mlflow/mlruns
    command: mlflow server --backend-store-uri ./mlruns --default-artifact-root ./mlruns --host 0.0.0.0 --port 5000
